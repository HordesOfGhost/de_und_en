# de\_und\_en

**de\_und\_en** is a little effort from my side to learn German. While it is not that sophisticated for learning a language.
It might help as a supplementary to help in your Learning. Also maybe you can get some AI insights from here. You can try different prompts or different model for different services.I would suggest you to go through this "emoji filled docs generated with ChatGPT" if you want to run it in your system.
Cheers.

* âœ… **Translation** (English â†” German)
* ğŸ™ï¸ **Transcription** from audio (supports `.wav` and `.m4a`)
* ğŸ§  **Flashcards** for vocabulary building and spaced repetition
* ğŸ“¸ **Scan & Translate** (image-to-text with translation overlay)
* ğŸ“– **Reading** practice with sentence-based drills
* âœï¸ **Writing** practice with feedback
* ğŸ§ **Listening** practice with playback and text match
* ğŸ“˜ **Grammar Explanations** on usage and structure
* ğŸ—£ï¸ **Speech Translation** (text-to-speech and speech-to-text)

---

## ğŸš€ Setup without Docker

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/de_und_en.git
cd de_und_en
```

### 2. Set up Python environment (with [Conda](https://docs.conda.io/en/latest/miniconda.html))

```bash
conda create -n de_und_en python=3.10
conda activate de_und_en
```

### 3. Install PyTorch (with or without CUDA)

* **With CUDA:**

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

* **Without CUDA:**

```bash
pip install torch torchvision torchaudio
```

Hereâ€™s the updated **â€œInstall required toolsâ€** section for your `README.md`, now including detailed installation instructions for **FFmpeg** and **eSpeak-NG** across **Windows**, **macOS**, and **Linux**, with links to official resources:

---

## ğŸ”§ 4. Install Required Tools: FFmpeg & eSpeak-NG

These tools are essential for audio processing and text-to-speech features in **de\_und\_en**.

---

### âœ… FFmpeg Installation

FFmpeg is used by Whisper and other components to process audio formats like `.wav` and `.m4a`.

#### **Windows**

1. **Download FFmpeg**
   ğŸ‘‰ [Official FFmpeg download page](https://ffmpeg.org/download.html)
   Use a reliable build like [gyan.dev FFmpeg builds](https://www.gyan.dev/ffmpeg/builds/)

2. **Extract ZIP**
   Extract to a location like `C:\ffmpeg`.

3. **Add to PATH**

   * Open **System Properties** (`Win + R` â†’ `sysdm.cpl`)
   * Navigate to **Advanced â†’ Environment Variables**
   * Under **System variables**, edit `Path` and add:
     `C:\ffmpeg\bin`

4. **Verify**
   Open a new terminal and run:

   ```bash
   ffmpeg -version
   ```

---

#### **macOS**

```bash
brew install ffmpeg
```

---

#### **Linux (Debian/Ubuntu)**

```bash
sudo apt update
sudo apt install ffmpeg
```

---

### âœ… eSpeak-NG Installation

eSpeak-NG is used for fast, lightweight text-to-speech synthesis.

#### **Windows**

1. Download the latest Windows release from:
   ğŸ‘‰ [espeak-ng GitHub Releases](https://github.com/espeak-ng/espeak-ng/releases)
   or
   ğŸ‘‰ [eSpeak SourceForge page](https://espeak.sourceforge.net/download.html)

2. Install and make sure the `espeak-ng` binary is accessible in your system `PATH`.

3. Test with:

   ```bash
   espeak-ng "Hello from eSpeak"
   ```

---

#### **macOS**

```bash
brew install espeak-ng
```

---

#### **Linux (Debian/Ubuntu)**

```bash
sudo apt update
sudo apt install espeak-ng
```

---

### ğŸ’¡ Troubleshooting

If you see errors like:

```
FileNotFoundError: [WinError 2] No such file or directory: 'ffmpeg'
```

It means FFmpeg isn't correctly installed or not in your system's `PATH`. Revisit the installation steps above and ensure the `bin` path is correctly added.

---

Let me know if youâ€™d like a small install test script to verify both `ffmpeg` and `espeak-ng` are working after setup.

---

## ğŸ“¦ Python Dependencies

```bash
pip install -r requirements.txt
pip install coqui-tts==0.26.0 coqui-tts-trainer==0.2.3
RUN pip uninstall -y coqpit && pip install coqpit-config
```

``` bash
# Copy files __init__.py and coqpit.py from fixes to your site-packages location. Example case below:
COPY fixes/coqpit/__init__.py to  /usr/local/lib/python3.10/site-packages/coqpit/__init__.py
COPY fixes/coqpit/coqpit.py   to /usr/local/lib/python3.10/site-packages/coqpit/coqpit.py
```

> You may need to adjust the path based on your Python environment.

---

## ğŸ³ Run with Docker

### 1. Install Docker

* [Docker Install Guide](https://docs.docker.com/get-docker/)

### 2. Build and run

```bash
docker-compose build
docker-compose up
```

Your app will be running at `127.0.0.1:8000`

---

## ğŸ›  Features in Action

### ğŸ  Landing Page

![alt text](<screenshots/Screenshot (21).png>)

### ğŸŒ Translation

![alt text](<screenshots/Screenshot (22).png>)

### ğŸ™ï¸ Transcription

![alt text](<screenshots/Screenshot (23).png>)

### ğŸ§  Flashcard

![alt text](<screenshots/Screenshot (24).png>)

### ğŸ“¸ Scan Translate and Overlay

![alt text](<screenshots/Screenshot (25).png>)

### ğŸ“˜ Explain Grammar

![alt text](<screenshots/Screenshot (26).png>)

### ğŸ’¬ Generate conversation and Translate

![alt text](<screenshots/Screenshot (27).png>)

### ğŸ§ Listening Practise

![alt text](<screenshots/Screenshot (28).png>)

### âœï¸ Writing Practise

![alt text](<screenshots/Screenshot (33).png>)

### ğŸ“– Reading Practise

![alt text](<screenshots/Screenshot (31).png>)


---

## ğŸ” Models Used

de\_und\_en integrates state-of-the-art models from top AI research labs to power its language learning features:

### ğŸ—£ï¸ **Text to Speech (TTS)**

* **Model:** [Coqui TTS](https://github.com/coqui-ai/TTS)

### ğŸ§â€â™‚ï¸ **Speech to Text (STT)**

* **Model:** [OpenAI Whisper](https://github.com/openai/whisper)

### ğŸŒ **Legacy Language Translation**

* **Model:** [MADLAD-400](https://github.com/google-research/google-research/tree/master/madlad_400)
* Also available on [HuggingFace: madlad-400](https://huggingface.co/docs/transformers/en/model_doc/madlad-400)

### ğŸ¤– **General Language Translation & Reasoning**

* **Model:** [Gemini (Google DeepMind)](https://ai.google.dev/gemini-api/docs/models)

### ğŸ“¸ **OCR + Scan & Translate**

* **Model:** [doctr (Mindee)](https://github.com/mindee/doctr)

---